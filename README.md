This is the repo of the work during my internship at Oak Ridge National Laboratory. My research was done in the context of the broader research project of developing drug development pipelines that make use of machine learning models. In this pipeline, first a generative model generates some organic molecule, and then a predictive model determines the properties of the molecule, such as how it affects different systems in the body. My work focused on the predictive model, and looked at a novel way to combine language models and graph neural networks (GNNs) to better determine properties of these input molecules. Specifically, I looked at using embeddings from from a chemical language model (CLM) as features on nodes (which represented atoms) to input to the graph neural network. I compared this approach with the base CLM and other GNN baselines, and was able to use the Frontier supercomputer to perform large-scale hyperparameter optimization to make a fair comparison between the methods. I ultimately found that the combined method did not end up significantly improving performance on the examined datasets. With the help of my mentor, I was able to get this work published as a workshop paper at the AI 4 Materials workshop at NeurIPS 2024. If I were to improve on this work for publication as a full paper, I would examine different methods to combine CLMs and GNNs, especially directly training both models to output into the same embedding space, instead of using CLM embeddings at nodes.

As a fair warning, the code in this repo is quite messy.

[Link to paper](https://openreview.net/pdf?id=YVnTOmu9a8)
